<!DOCTYPE html>
<html lang="en-US" dir="ltr">

    <head>
        <!-- Header -->
        <script language="javascript" type="text/javascript" src="https://www.bbgatch.com/header.js"></script>
        <title>bbgatch | Forecasting TSA Data with R</title>
    </head>

    <body>
        <h1>Forecasting TSA Data with R</h1>
            <p><i>2024-10-05</i></p>
            
        <!-- TODO:
            - Finish the final forecast and summarize functions.
            - Create plots showing ARIMA/ETS final forecasts and final plot with intervals
            - Check alt text
        -->

            <p>If we want to create a forecast in R for the TSA Passenger data to predict passenger volumes in the future, we can use the <a href="https://tidyverts.org">tidyverts packages</a> `fable`, `tsibble`, and `feasts`.</p>

            <p>These packages apply <a href="https://r4ds.had.co.nz/tidy-data.html">tidy data principles</a> to time series data and forecasting. They were coauthored by the forecasting great <a href="https://robjhyndman.com">Rob Hyndman</a>. If you are interested in learning more about forecasting, I highly recommend Rob Hyndman and George Athanasopoulos's fantastic textbook: <a href="https://otexts.com/fpp3/">Forecasting: Principles and Practice (3rd Edition) (FPP3)</a>, which uses these tidyverts packages and workflows.</p>
            
            <h2>Plotting the History</h2>
                <p>The historical TSA Passenger data that we have looks like this:</p>
                <img src="images/tsa-passenger-history.png" alt="Line plot of TSA Passenger History." class="responsive" width="80%">

                <p><a href="https://www.bbgatch.com/projects/tsa/2024-08-27-how-much-history-to-use-forecasting-tsa-data/2024-08-27-how-much-history-to-use-forecasting-tsa-data.html">We recently learned</a> that our models will likely perform best if we ignore pre-Covid data and just assume history begins at April 2020. So we will use that in our model selection and final forecasts here.</p>
                
                <p>There is clear seasonality in the data, and there has been an upward trend coming out of the Covid downturn.</p>
                <img src="images/time-series-decomposition.png" alt="Line plots decomposing TSA Passenger History time series into trend, seasonality, and remainder components." class="responsive" width="80%">
                
            <h2>Evaluating Models with a Train/Test Split</h2>
                <p>The <code>fable</code> package provides several time series models to choose from. We can evaluate which models perform the best by breaking our data into separate train/test sets. We then fit each model on the training data, generate a forecast from each model over the test set time period, and we evaluate each model's forecast against our test set to measure accuracy.</p>
                
                <p>We'll start with <a href="https://otexts.com/fpp3/simple-methods.html">four simple baseline models</a> that allow us to compare our more complex models against simple but still effective baselines. We'll use the <code>ARIMA</code> function to find the best fitting ARIMA model, and we'll try four different ETS models. We know that trend and seasonality is likely to continue, so we will limit ourselves to just these ETS models, but you could try others. Alternatively, the <code>ETS()</code> function can select the best-fitting ETS model for you, just like the <code>ARIMA()</code> function.</p>
                
                <pre><code class="language-r">
                    fit <- train |> model(
                        # Baseline models
                        mean = MEAN(passengers),
                        naive = NAIVE(passengers),
                        drift = NAIVE(passengers ~ drift()),
                        snaive = SNAIVE(passengers),
                        # tslm = TSLM(passengers ~ trend() + season()),
                        
                        # Auto-ARIMA and Auto-ETS models
                        arima = ARIMA(passengers, stepwise=FALSE, approximation=FALSE),
                        # ets = ETS(passengers),
                
                        # Specify ETS models
                        ets_aaa = ETS(passengers ~ error('A') + trend('A') + season('A')),
                        ets_aada = ETS(passengers ~ error('A') + trend('Ad') + season('A')),
                        ets_aam = ETS(passengers ~ error('A') + trend('A') + season('M')),
                        ets_aadm = ETS(passengers ~ error('A') + trend('Ad') + season('M'))                
                </code></pre>

                <img src="images/train-test-model-accuracy-initial.png" alt="Terminal output of initial forecast model results." class="responsive" width="80%">
                
                <p>Thankfully our ARIMA and ETS model do outperform our baselines. The <code>arima</code> model performs the best and <code>ets_aada</code> is second. The models with multiplicative seasonality don't perform as well and actually underperform some of our baselines.</p>
                
                <p>One nice feature of <code><a href="https://fable.tidyverts.org">fable</a></code> is that it makes it very easy to <a href="https://otexts.com/fpp3/combinations.html">combine or ensemble multiple forecast models.</a> Hyndman and Athanasopoulos describe this as such:</p>

                <blockquote class="highlighted">"The results have been virtually unanimous: combining multiple forecasts leads to increased forecast accuracy. In many cases one can make dramatic performance improvements by simply averaging the forecasts."</blockquote>

                <p>Based on our results, we'll try creating combined forecasts of the <code>arima</code> model with the <code>ets_aada</code> and <code>ets_aaa</code> models.</p>

                <pre><code class="language-r">
                    # Create combined models
                    fcst <- fit |> mutate(
                        arima_ets_aaa = (arima + ets_aaa) / 2,
                        arima_ets_aada = (arima + ets_aada) / 2,
                    ) |> forecast(h = months_to_forecast)
                    
                    # View model forecast accuracy against test set
                    accuracy(fcst, df) |>
                        arrange(RMSE)
                </code></pre>

                <img src="images/train-test-model-accuracy-add-combos.png" alt="Terminal output of forecast model results when adding combination models." class="responsive" width="80%">
                
                <p>After adding in our two combined models, the plain ARIMA model still performs the best, but the two combined models are second and third.</p>
                
                <p>We can plot the forecasts from each model to see how they compare:</p>

                <img src="images/train-test-top-forecast-models.png" alt="Line plot showing performance of top forecast models." class="responsive" width="80%">

                <p>Based on these results, I would pick either the <code>arima</code> or the <code>arima_ets_aada</code> model. While the <code>arima</code> model is more accurate compared to the test set, over the long term I would probably prefer to use an ensemble model.</p>
                
            <h2>Evaluating Models with Cross Validation</h2>
                <p>Another approach to time series model evaluation is <a href="https://otexts.com/fpp3/tscv.html">cross validation</a>. This is a little different from cross validation you may have used in other machine learning contexts. With time series data, we start with an initial base set of only <i>n</i> historical data points, fit our models, calculate forecasts, and measure accuracy. We then repeat the process by adding one additional data point (or more) to the base set of historical data with each step, fit the moels, forecast, and measure accuracy. In each iteration we're forecasting one or more steps out. Prof. Hyndman uses this visualization below in his textbook to help explain the process. The blue dots are the base history we're using to fit our models, and the orange dots are the future points we're trying to estimate:</p>

                <img src="images/fpp3-cross-validation.png" alt="" class="responsive" width="60%">
                
                <p>One neat benefit of this approach is that if we're forecasting more than one step ahead in each iteration we can see the average model accuracy across all of the CV sets at 1 to <i>n</i> steps out. As we'd expect, model accuracy gets worse the further out we try to forecast. We can see that the best performing model across the CV sets is the ETS(A,Ad,A) model, and the second best is the combination of ARIMA and ETS(A,Ad,A).</p>
                <img src="images/cross-validation-forecast-error.png" alt="" class="responsive" width="80%">
                
                <p>The total model accuracy across all CV steps and forecast periods is below. It's also possible to calculate the accuracy just for <i>n</i> specific forecast steps out.</p>

                <img src="images/cross-validation-model-accuracy.png" alt="" class="responsive" width="80%">

            <h2>Final Forecast</h2>
                <p>Based on what we've seen by evaluating different models with a train/test split and cross-validation, we know that the ARIMA and ETS(A,Ad,A) models tend to perform the best, along with the combination of the two. The train/test split method put ARIMA at the top, but cross validation put ETS(A,Ad,A) at the top. Ultimately, I would choose the combination of the two so that we can hopefully gain from the benefits of ensembling.</p>

                <p>Let's perform a final forecast, fitting ARIMA and ETS(A,Ad,A) models on the full dataset. This is what each model, and the combined model, look like. We can see that the arima forecast is slightly lower and the ets_aada forecast is slightly higher, and the combined model is the average of the two, running through the middle. The 80% and 95% prediction intervals are shown by default in the <code>autoplot()</code> function in the <code>tidyverts</code> packages. Both models give very similar forecasts, and it looks like they're accurately capturing a very reasonable trend and seasonality.</p>

                <img src="images/final-forecast-three-models.png" alt="" class="responsive" width="80%">
                
                <p>Finally, let's plot just the point forecast of the final chosen combined model with the full history.</p>
                
                <img src="images/final-forecast.png" alt="" class="responsive" width="80%">
                
            <h2>Conclusions</h2>
                <p>In this case, we're forecasting through the end of this year and through all of next year. Let's look at what the forecsat is telling us the total annual growth will be in TSA passengers for this year and next.</p>

                <pre><code>
                    # Calculate annual percent change in TSA Passengers
                    df |>
                        as_tibble() |>
                        mutate(Year = year(date)) |>
                        group_by(Year) |>
                        summarize(passengers = sum(passengers)) |>
                        arrange(Year) |>
                        mutate(pct_chg = percent((passengers / lag(passengers) - 1)))
                </code></pre>

                <img src="images/final-forecast-annual-change.png" alt="" class="responsive" width="30%">

                <!-- <embed src="output.html">
                <embed src="output.html" width="250" height="550">
                <center><embed src="output.html" width="250" height="550"></center> -->
                
                <!-- <div id="output"></div>
                <script>
                    fetch('output.html')
                        .then(response => response.text())
                        .then(data => {
                            document.getElementById('output').innerHTML = data;
                        });
                </script> -->

                <p>The forecast is showing 2024 will finish the year up +4.9% and 2025 will growth +3.8%. This looks entirely reasonable.</p>
            
            <a href="https://github.com/bbgatch/bbgatch.github.io/blob/main/projects/tsa/forecasting-tsa-data-with-r/forecast-tsa-data.R">
            <h2>Full Code</h2>
            </a>
                <pre><code class="language-r">
                </code></pre>

        <!-- Footer -->
        <script language="javascript" type="text/javascript" src="https://www.bbgatch.com/footer.js"></script>

    </body>

</html>
